# import gzip
# import json
# import re
# import uuid
# from pathlib import Path
# from textwrap import wrap
# import os
#
# import pandas as pd
# import matplotlib.pyplot as plt
# import plotly.express as px
# import seaborn as sns
# import numpy as np
#
# sns.set_theme(style="ticks")
#
# Path("data/testing/plots").mkdir(parents=True, exist_ok=True)
#
# OUTPUT_FOLDER = Path(os.path.join('..', 'tests', 'data', 'testing')) # TODO: change it to the dir above data/testing/plots
#
#
# def delete_double_gz() -> pd.DataFrame:
#     output_dir = Path("data/testing")
#     run_dirs = list(f for f in output_dir.iterdir() if f.name.startswith("["))
#     for run_dir in run_dirs:
#         files = list(run_dir.iterdir())
#         for file in files:
#             suffixes = file.suffixes
#             if len(suffixes) > 1 and suffixes[-1] == ".gz" and suffixes[-2] == ".gz":
#                 with gzip.open(file, "rb") as f_in, open(file.with_suffix(""), "wb") as f_out:
#                     f_out.writelines(f_in)
#                 os.remove(file)
#
#
# def load_sorted_oligos_to_df() -> pd.DataFrame:
#     import csv
#     output_dir = Path("data/testing")
#     run_dirs = list(f for f in output_dir.iterdir() if f.name.startswith("SS"))
#     sorted_files = []
#
#     for run_dir in run_dirs:
#         try:
#             sorted_file = [f for f in run_dir.iterdir() if "sort_oligo_results_file" in f.name][0]
#         except IndexError:
#             continue
#         sorted_files.append(sorted_file)
#     print(f'sort_oligo_results_file')
#     info_list = []
#
#     with open("sorted_oligos.csv", 'w') as csvfile:
#         fieldnames = ["uid", "barcode", "read_len"]
#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
#         writer.writeheader()
#         for sorted_file in sorted_files:
#             uid = uuid.uuid4()
#             try:
#                 with gzip.open(sorted_file, "rb") as f:
#                     for line in f:
#                         line = line.strip()
#                         writer.writerow({
#                             "uid": uid,
#                             "barcode": line[:12].decode(),
#                             "read_len": len(line[12:]),
#                         })
#             except:
#                 print(sorted_file)
#                 print(line)
#
#     print(f'info_list')
#
#     df_reads = pd.read_csv("sorted_oligos.csv")
#     return df_reads
#
#
# def draw_reads_histograms(df: pd.DataFrame):
#     plt.subplots()
#     fig = sns.histplot(df["read_len"], kde=False)
#     fig.set_ylabel("count")
#     fig = plt.gcf()
#     fig.savefig(Path("data/testing/plots") / "read_len_count")
#
#     groups = df.groupby(["uid", "barcode"])
#     reads_per_barcode = []
#     for _, group in groups:
#         reads_per_barcode.append({"reads": len(group)})
#
#     plt.subplots()
#     # how many lines (sequences) was read per each barcode.
#     # (That's why we have concentrations around 20, 50, 100, 1000)
#     df_reads_per_barcode = pd.DataFrame(reads_per_barcode)
#     fig = sns.histplot(df_reads_per_barcode["reads"], kde=False, binwidth=1)
#     fig.set_ylabel("count")
#     fig.set_xlabel("number of reads per barcode")
#     fig = plt.gcf()
#     fig.savefig(Path("data/testing/plots") / "number of reads per barcode")
#
#
# def load_data_to_df() -> pd.DataFrame:
#     # output_dir = Path("data/testing")
#
#     run_dirs = list(f for f in OUTPUT_FOLDER.iterdir() if f.name.startswith("[SS"))
#
#     json_files = []
#
#     for run_dir in run_dirs:
#         try:
#             json_file = [f for f in run_dir.iterdir() if f.suffix == ".json"][0]
#         except IndexError:
#             continue
#         json_files.append(json_file)
#
#     info_list = []
#
#     for json_file in json_files:
#         with json_file.open("rb") as f:
#             info = json.load(f)
#         info_list.append(info)
#
#     df = pd.DataFrame(info_list)
#     df["output_dir"] = df["output_dir"].apply(lambda x: x.split("data/testing/")[1].split(" trial")[0])
#
#     df.to_csv(f'{OUTPUT_FOLDER}/df_all_data.csv', index=False)
#     return df
#
#
# def draw_boxplots(df: pd.DataFrame, percentage: bool = False):
#     trials_group = df.groupby([
#         'number_of_oligos_per_barcode',
#         'number_of_sampled_oligos_from_file',
#         'size',
#         'bits_per_z'
#     ])
#
#     errors = ["substitution_error", "deletion_error", "insertion_error"]
#     y_values = ["levenshtein_distance", "levenshtein_distance_sigma_before_rs",
#                 "levenshtein_distance_sigma_after_rs_payload", "levenshtein_distance_sigma_after_rs_wide"]
#     for y in y_values:
#         if y == "levenshtein_distance":
#             palette = "Purples"
#         else:
#             palette = "Blues"
#         for idx, trial_group in trials_group:
#             fig, axes = plt.subplots(nrows=3)
#             fig.suptitle("\n".join(
#                 wrap(trial_group["output_dir"].iloc[0].split("errorsSub")[0] + f"\n{y}".replace("_", " "), 71)))
#             fig.subplots_adjust(top=0.85, hspace=0.5)
#             for ax, error in zip(axes, errors):
#                 zero_cols = [e for e in errors if e != error]
#                 df_for_err = trial_group
#                 for col in zero_cols:
#                     df_for_err = df_for_err[df_for_err[col] == 0]
#                 if percentage:
#                     ×–ax = sns.barplot(x=error, y=y, data=df_for_err, estimator=estimate, ax=ax, palette=palette)
#                     ax.set(ylabel="Full reconstraction rate")
#                 else:
#                     ax = sns.boxplot(x=error, y=y, data=df_for_err, ax=ax, palette=palette)
#                     ax = sns.swarmplot(x=error, y=y, data=df_for_err, color=".25", ax=ax)
#                     ax.set(ylabel="Normlized Levenshtein distance")
#             if percentage:
#                 fig.savefig(Path("data/testing/plots") / " ".join(wrap(
#                     trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
#                                                                                                       " ") + f"{y} success",
#                     71)))
#                 plt.close(fig)
#             else:
#                 fig.savefig(Path("data/testing/plots") / "".join(wrap(
#                     trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
#                                                                                                       " ") + f"{y}",
#                     71)))
#                 plt.close(fig)
#
#
# def draw_boxplots_all_samples(df: pd.DataFrame, percentage: bool = False):
#     trials_group = df.groupby([
#         'number_of_oligos_per_barcode',
#         'size',
#         'bits_per_z'
#     ])
#
#     errors = ["substitution_error", "deletion_error", "insertion_error"]
#     y_values = {"levenshtein_distance": "input_text_len",
#                 "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
#                 "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
#                 "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
#                 }
#     for y_value in y_values.items():
#         df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
#     for y in y_values:
#         if y == "levenshtein_distance":
#             palette = "Purples"
#         else:
#             palette = "Blues"
#         for idx, trial_group in trials_group:
#             fig, axes = plt.subplots(nrows=3)
#             title = trial_group["output_dir"].iloc[0].split("errorsSub")[0] + f"\n{y}".replace("_", " ")
#             title = re.sub(r'\[ number of oligos sampled after synthesis[^\S\n\t]+\d+[^\S\n\t]+\]', '', title)
#             fig.suptitle("\n".join(wrap(title, 71)))
#             fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
#             for ax_idx, (ax, error) in enumerate(zip(axes, errors)):
#                 zero_cols = [e for e in errors if e != error]
#                 df_for_err = trial_group
#                 for col in zero_cols:
#                     df_for_err = df_for_err[df_for_err[col] == 0]
#                 if percentage:
#                     ax = sns.barplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err,
#                                      estimator=estimate, ax=ax, palette=palette)
#                     ax.set(ylabel="Full reconstraction rate")
#                 else:
#                     ax = sns.boxplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err, ax=ax,
#                                      palette=palette)
#                     # ax = sns.swarmplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err, ax=ax, dodge=True, palette=palette)
#                     ax.set(ylabel="Normlized Levenshtein distance")
#                 if ax_idx != 0:
#                     ax.get_legend().remove()
#                 else:
#                     ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
#             if percentage:
#                 fig.savefig(Path("data/testing/plots") / " ".join(wrap(
#                     trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
#                                                                                                       " ") + f"{y} success",
#                     71)))
#                 plt.close(fig)
#             else:
#                 fig.savefig(Path("data/testing/plots") / "".join(wrap(
#                     trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
#                                                                                                       " ") + f"{y}",
#                     71)))
#                 plt.close(fig)
# '''
# Fig 1:
# Title = Normalized LD as a function of sample size (No error correction)
# Subplots = error type (share X axis, X-ticks only on the buttom, no titles for subplots)
# X = number of reads (10-100)
# Y = Normalized distance (with error bars)
# Color = error level {0,0.01}
# Filter: size = 5
# Caption: ...'''
# def draw_errorbar_10_100sample_and_0_001_error_errortypes(df: pd.DataFrame, percentage: bool = False):
#     samples = [10, 20, 50, 100]
#     error_values = [0.01, 0]
#     size = [5]
#
#     trials_group = df.groupby([
#         'number_of_oligos_per_barcode',
#         'size',
#         'bits_per_z'
#     ])
#
#     error_types = ["substitution_error", "deletion_error", "insertion_error"]
#     y_values = {
#                 "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len"
#                 }
#     colors = ['-b', '-r']
#
#     plt.figure(figsize=(20, 15))
#
#     for y_value in y_values.items():
#         df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
#     for idx, trial_group in trials_group:
#         if idx[1] not in size:
#             continue
#
#         title = 'Normalized LD as a function of sample size (No error correction)'
#         # fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
#         for ax_idx, error_type in enumerate(error_types):
#             plt.subplot(3,1,(ax_idx+1))
#             zero_cols = [e for e in error_types if e != error_type]
#             df_for_err = trial_group
#             for col in zero_cols:
#                 df_for_err = df_for_err[df_for_err[col] == 0]
#
#             # Filter by cols error_value and number_of_sampled_oligos_from_file
#             for error_value, color_value in zip(error_values, colors):
#
#                 df_for_err_filtered = df_for_err.where(df_for_err[error_type] == error_value)
#                 df_for_err_filtered = df_for_err_filtered[
#                     df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]
#
#                 grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')['levenshtein_distance_sigma_before_rs'].apply(list)
#                 result = {key: value for key, value in grouped.to_dict().items()}
#
#                 std_error = np.std(list(result.values()), axis=1)
#                 mean_error = np.mean(list(result.values()), axis=1)
#
#                 plt.errorbar(samples, mean_error, yerr=std_error, fmt=color_value, markersize=15,
#                              elinewidth=1, capsize=3, label=0, linewidth=3)
#
#
#             ylim = [-0.01, 1]
#             yticks = np.linspace(0, 1, 6)
#             plt.ylim(ylim)
#             plt.yticks(yticks)
#             plt.title(error_type.replace("_", " "), size=20)
#             plt.legend(error_values, title='Error rate', prop={'size': 15}, title_fontsize=15)
#
#
#         plt.text(20, 3.6, title, va='bottom', rotation='horizontal', fontsize=30)
#         plt.text(35, -0.3, 'Number of sampled oligos from file', va='bottom', rotation='horizontal', fontsize=30)
#         plt.text(-0.1, 1.8, 'Normlized Levenshtein distance', va='center', rotation='vertical', ha='right', fontsize=30)
#         plt.savefig(Path("data/testing/plots") / "".join(wrap(title, 71)))
#         plt.close()
#
# # Fig draw_lineplot_in_one_graph:
# # Title = Normalized LD as a function of sample size error=0.01 (No error correction)
# # X = number of reads (10-100)
# # Y = Normalized distance (with error bars, show the zero!)
# # Color = error type {S,I,D}
# # Filter: size = 5
# # def draw_errorbar_in_one_graph(df: pd.DataFrame, is_normalize_data, percentage: bool = False):
# #     # samples = [10, 20, 50, 100]
# #     # samples = [10, 20, 50, 100, 200]
# #     samples = [1, 4, 6, 10, 20, 30, 40]
# #     error_values = [0.01]
# #     size = [4]
# #     title_start = ""
# #
# #     trials_group = df.groupby([
# #         'number_of_oligos_per_barcode',
# #         'size',
# #         'bits_per_z'
# #     ])
# #
# #     errors = ["substitution_error", "deletion_error", "insertion_error"]
# #     y_values = {
# #         "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
# #         "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
# #         "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
# #     }
# #     if is_normalize_data:
# #         title_start = "Normalized "
# #         for y_value in y_values.items():
# #             df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
# #
# #     for idx, trial_group in trials_group:
# #         if idx[1] not in size:
# #             continue
# #         for y_value in y_values.keys():
# #             title = title_start + "LD as a function of sample size. Error=0.01, 0 (No error correction)\n" + y_value
# #             fig, ax = plt.subplots(figsize=(8, 6))
# #
# #             fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
# #             for ax_idx, error in enumerate(errors):
# #                 zero_cols = [e for e in errors if e != error]
# #                 df_for_err = trial_group
# #                 for col in zero_cols:
# #                     df_for_err = df_for_err[df_for_err[col] == 0]
# #
# #                 if error == "deletion_error":
# #                     error_values.append(0)
# #
# #                 for error_value in error_values:
# #                     df_for_err_filtered = df_for_err.where(df_for_err[error] == error_value)
# #                     df_for_err_filtered = df_for_err_filtered[
# #                         df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]
# #
# #                     grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
# #                         y_value].apply(list)
# #                     result = {key: value for key, value in grouped.to_dict().items()}
# #
# #                     std_error = np.std(list(result.values()), axis=1)
# #                     mean_error = np.mean(list(result.values()), axis=1)
# #
# #                     if error == "deletion_error" and error_value == 0:
# #                         plt.errorbar(samples, mean_error + 0.004, yerr=std_error, markersize=15,
# #                                      elinewidth=1, capsize=3,
# #                                      label='all errors' + ' ' + str(error_value), linewidth=3)
# #                     else:
# #                         plt.errorbar(samples, mean_error, yerr=std_error, markersize=15,
# #                                      elinewidth=1, capsize=3, label=error.replace("_error", "")+' '+str(error_value), linewidth=3)
# #
# #                 if error == "deletion_error":  # reset your error_values list after processing substitution_error
# #                     error_values.remove(0)
# #
# #                 plt.legend(fontsize=18)
# #                 ax.tick_params(axis='x', labelsize=20)
# #                 ax.tick_params(axis='y', labelsize=20)
# #                 ax.set_xlabel('#Simulated Reads Per Sequence (Mean)', x=0.5, y=-5, fontsize=20)
# #                 ax.set_ylabel(title_start+'Levenshtein Distance', fontsize=20)
# #
# #                 if is_normalize_data:
# #                     ax.set_ylim(-0.01, 1)
# #                 else:
# #                     ax.set_ylim(-0.01, 10000)
# #
# #             # plt.title(title)
# #             fig.tight_layout()
# #             fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
# #             plt.close(fig)
#
# # def draw_errorbar_in_one_graph(df: pd.DataFrame, is_normalize_data, percentage: bool = False):
# #     # samples = [10, 20, 50, 100]
# #     samples = [1,4, 6,10, 20, 30, 40]
# #     error_values = [0.01]
# #     size = [4]
# #     title_start = ""
# #
# #     trials_group = df.groupby([
# #         'number_of_oligos_per_barcode',
# #         'size',
# #         'bits_per_z'
# #     ])
# #
# #     errors = ["substitution_error", "deletion_error", "insertion_error"]
# #     y_values = {
# #         "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
# #         "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
# #         "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
# #     }
# #     if is_normalize_data:
# #         title_start = "Normalized "
# #         for y_value in y_values.items():
# #             df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
# #
# #     for idx, trial_group in trials_group:
# #         if idx[1] not in size:
# #             continue
# #         for y_value in y_values.keys():
# #             title = title_start + "LD as a function of sample size. Error=0.01, 0 (No error correction)\n" + y_value
# #             fig, ax = plt.subplots(figsize=(8, 6))
# #
# #             fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
# #             for ax_idx, error in enumerate(errors):
# #                 zero_cols = [e for e in errors if e != error]
# #                 df_for_err = trial_group
# #                 for col in zero_cols:
# #                     df_for_err = df_for_err[df_for_err[col] == 0]
# #
# #                 if error == "deletion_error":
# #                     error_values.append(0)
# #
# #                 for error_value in error_values:
# #                     df_for_err_filtered = df_for_err.where(df_for_err[error] == error_value)
# #                     df_for_err_filtered = df_for_err_filtered[
# #                         df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]
# #
# #                     grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
# #                         y_value].apply(list)
# #                     result = {key: value for key, value in grouped.to_dict().items()}
# #
# #                     std_error = np.std(list(result.values()), axis=1)
# #                     mean_error = np.mean(list(result.values()), axis=1)
# #
# #                     if error == "deletion_error" and error_value == 0:
# #                         plt.errorbar(samples, mean_error + 0.004, yerr=std_error, markersize=15,
# #                                      elinewidth=1, capsize=3,
# #                                      label='all errors' + ' ' + str(error_value), linewidth=3)
# #                     else:
# #                         plt.errorbar(samples, mean_error, yerr=std_error, markersize=15,
# #                                      elinewidth=1, capsize=3, label=error.replace("_error", "")+' '+str(error_value), linewidth=3)
# #
# #                 if error == "deletion_error":  # reset your error_values list after processing substitution_error
# #                     error_values.remove(0)
# #
# #                 plt.legend()
# #                 ax.set_xlabel('sampled oligos from file', x=0.5, y=-5)
# #                 ax.set_ylabel(title_start+'Levenshtein distance')
# #
# #                 if is_normalize_data:
# #                     ax.set_ylim(-0.00001, 0.1)
# #                 else:
# #                     ax.set_ylim(-0.01, 10000)
# #
# #             # plt.title(title)
# #             fig.tight_layout()
# #             fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
# #             plt.close(fig)
#
# def draw_errorbar_in_one_graph(df: pd.DataFrame, is_normalize_data, percentage: bool = False):
#     # samples = [10, 20, 50, 100]
#     samples = [6, 10, 20, 30, 40]
#     error_values = [0.01]
#     size = [4]
#     title_start = ""
#
#     trials_group = df.groupby([
#         'number_of_oligos_per_barcode',
#         'size',
#         'bits_per_z'
#     ])
#
#     errors = ["substitution_error", "deletion_error", "insertion_error"]
#     y_values = {
#         "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
#         "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
#         "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
#     }
#     if is_normalize_data:
#         title_start = "Normalized "
#         for y_value in y_values.items():
#             df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
#
#     for idx, trial_group in trials_group:
#         if idx[1] not in size:
#             continue
#         for y_value in y_values.keys():
#             title = title_start + "LD as a function of sample size. Error=0.01, 0 (No error correction)\n" + y_value
#             fig, ax = plt.subplots(figsize=(8, 6))
#
#             fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
#             for ax_idx, error in enumerate(errors):
#                 zero_cols = [e for e in errors if e != error]
#                 df_for_err = trial_group
#                 for col in zero_cols:
#                     df_for_err = df_for_err[df_for_err[col] == 0]
#
#                 if error == "deletion_error":
#                     error_values.append(0)
#
#                 for error_value in error_values:
#                     df_for_err_filtered = df_for_err.where(df_for_err[error] == error_value)
#                     df_for_err_filtered = df_for_err_filtered[
#                         df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]
#
#                     grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
#                         y_value].apply(list)
#                     result = {key: value for key, value in grouped.to_dict().items()}
#
#                     std_error = np.std(list(result.values()), axis=1)
#                     mean_error = np.mean(list(result.values()), axis=1)
#
#                     if error == "deletion_error" and error_value == 0:
#                         plt.errorbar(samples, mean_error + 0.004, yerr=std_error, markersize=15,
#                                      elinewidth=1, capsize=3,
#                                      label='all errors' + ' ' + str(error_value), linewidth=3)
#                     else:
#                         plt.errorbar(samples, mean_error, yerr=std_error, markersize=15,
#                                      elinewidth=1, capsize=3, label=error.replace("_error", "")+' '+str(error_value), linewidth=3)
#
#                 if error == "deletion_error":  # reset your error_values list after processing substitution_error
#                     error_values.remove(0)
#
#                 plt.legend()
#                 ax.set_xlabel('sampled oligos from file', x=0.5, y=-5)
#                 ax.set_ylabel(title_start+'Levenshtein distance')
#
#                 if is_normalize_data:
#                     ax.set_ylim(-0.01, 1)
#                 else:
#                     ax.set_ylim(-0.01, 10000)
#
#             # plt.title(title)
#             fig.tight_layout()
#             fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
#             plt.close(fig)
#
# # Fig draw_lineplot_in_one_graph:
# # Title = Normalized LD as a function of sample size error=0.01 (No error correction)
# # X = number of reads (10-100)
# # Y = Normalized distance (with error bars, show the zero!)
# # Color = error type {S,I,D}
# # Filter: size = 5
# # def draw_errorbar_in_one_graph(df: pd.DataFrame, percentage: bool = False):
# #     samples = [10, 20, 50, 100]
# #     error_values = [0.01]
# #     size = [5]
# #
# #     trials_group = df.groupby([
# #         'number_of_oligos_per_barcode',
# #         'size',
# #         'bits_per_z'
# #     ])
# #
# #     errors = ["substitution_error", "deletion_error", "insertion_error"]
# #     y_values = {
# #                 "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
# #                 }
# #
# #     for y_value in y_values.items():
# #         df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
# #     for idx, trial_group in trials_group:
# #         if idx[1] not in size:
# #             continue
# #         fig, ax = plt.subplots(figsize=(8,6))
# #
# #         title="Normalized LD as a function of sample size. Error=0.01 (No error correction)"
# #         fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
# #         for ax_idx, error in enumerate(errors):
# #             zero_cols = [e for e in errors if e != error]
# #             df_for_err = trial_group
# #             for col in zero_cols:
# #                 df_for_err = df_for_err[df_for_err[col] == 0]
# #
# #             for error_value in error_values:
# #                 df_for_err_filtered = df_for_err.where(df_for_err[error] == error_value)
# #                 df_for_err_filtered = df_for_err_filtered[
# #                     df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]
# #
# #                 grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
# #                     'levenshtein_distance_sigma_before_rs'].apply(list)
# #                 result = {key: value for key, value in grouped.to_dict().items()}
# #
# #                 std_error = np.std(list(result.values()), axis=1)
# #                 mean_error = np.mean(list(result.values()), axis=1)
# #
# #                 plt.errorbar(samples, mean_error, yerr=std_error, markersize=15,
# #                              elinewidth=1, capsize=3, label=error.replace("_error", ""), linewidth=3)
# #
# #             plt.legend()
# #             ax.set_xlabel('sampled oligos from file', x=0.5, y=-5)
# #             ax.set_ylabel('Normalized Levenshtein distance')
# #
# #             ax.set_ylim(-0.01, 1)
# #
# #         plt.title(title)
# #         fig.tight_layout()
# #         fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".png", 71)))
# #         plt.close(fig)
#
#
# # Fig draw_lineplot_before_after_rs:
# # Title = Reconstruction rates during the EC process
# # X = EC step {Raw input, After RS1, After 2D RS}
# # Y = Reconstruction rate (with error bars)
# # Color = error type {S,I,D}
# # Filter: size = 5, sample size = 50,
#
# # def draw_errorbar_before_after_rs(df: pd.DataFrame, percentage: bool = False):
# #     samples = [50]
# #     error_values = [0.01]
# #     size = [4]
# #
# #     trials_group = df.groupby([
# #         'number_of_oligos_per_barcode',
# #         'size',
# #         'bits_per_z'
# #     ])
# #     error_types = ["substitution_error", "deletion_error", "insertion_error"]
# #
# #     y_values = {
# #         "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
# #         "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
# #         "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
# #     }
# #     for y_value in y_values.items():
# #         df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
# #
# #     for idx, trial_group in trials_group:
# #         if idx[1] not in size:
# #             continue
# #         dfs = {}
# #         dfs_new = []
# #         for y in y_values:
# #             dfs[y] = pd.DataFrame(columns=error_types)
# #
# #             for error_type in error_types:
# #                 zero_cols = [e for e in error_types if e != error_type]
# #                 df_for_err = trial_group
# #                 for col in zero_cols:
# #                     df_for_err = df_for_err[df_for_err[col] == 0]
# #
# #                 for error_value in error_values:
# #                     df_for_err_filtered = df_for_err.where(df_for_err[error_type] == error_value)
# #                     df_for_err_filtered = df_for_err_filtered[
# #                         df_for_err_filtered['number_of_sampled_oligos_from_file'] == (samples[0])]
# #                     dfs[y][error_type] = df_for_err_filtered[y].values
# #             dfs_new.append(dfs[y].copy())
# #
# #         fig, ax = plt.subplots()
# #
# #         colors = ['blue', 'red', 'yellow']
# #
# #         df_out_before_rs = dfs_new[0]
# #         df_out_after_rs_payload = dfs_new[1]
# #         df_out_after_rs_wide = dfs = dfs_new[2]
# #
# #         for error_type, color in zip(error_types, colors):
# #             my_dict = {'before_rs': df_out_before_rs[error_type].values,
# #                        'after_rs_payload': df_out_after_rs_payload[error_type].values,
# #                        'after_rs_wide': df_out_after_rs_wide[error_type].values}
# #
# #             my_dict = {'before_rs': df_out_before_rs[error_type].values,
# #                        'after_rs_payload': df_out_after_rs_payload[error_type].values,
# #                        'after_rs_wide': df_out_after_rs_wide[error_type].values}
# #
# #         results = {key: value for key, value in my_dict.items()}
# #
# #
# #         if percentage:
# #             array_estimate = []
# #             for dict_value in list(my_dict.values()):
# #                 array_estimate.append([estimate(dict_value)])
# #
# #             std_error = np.std(array_estimate, axis=1)
# #             mean_error = np.mean(array_estimate, axis=1)
# #
# #             plt.errorbar(my_dict.keys(), mean_error, yerr=std_error, markersize=15,
# #                          elinewidth=1, capsize=3, label=error_type.replace("_error", ""), linewidth=3)
# #             title = 'Full reconstruction rates during the EC process'
# #             ax.set_ylabel('Full reconstruction rate')
# #
# #         else:
# #             std_error = np.std(list(my_dict.values()), axis=1)
# #             mean_error = np.mean(list(my_dict.values()), axis=1)
# #
# #             plt.errorbar(my_dict.keys(), mean_error, yerr=std_error, markersize=15,
# #                          elinewidth=1, capsize=3, label=error_type.replace("_error", ""), linewidth=3)
# #             title = 'Normalized Reconstruction rates during the EC process'
# #             ax.set_ylabel('Normalized Levenshtein distance')
# #
# #
# #         # save to file
# #
# #         fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".png", 71)))
# #         plt.close(fig)
#
# def draw_barplot_before_after_rs(df: pd.DataFrame, percentage: bool = False, is_normalize_data: bool = True):
#     samples = [30]
#     error_values = [0.01]
#     size = [4]
#
#     df_copy = df.copy(deep=True)
#     title_start_name = ""
#
#     trials_group = df_copy.groupby([
#         'number_of_oligos_per_barcode',
#         'size',
#         'bits_per_z'
#     ])
#     error_types = ["substitution_error", "deletion_error", "insertion_error"]
#
#     y_values = {
#         "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
#         "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
#         "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
#     }
#     if is_normalize_data:
#         title_start_name = 'Normalized '
#         for y_value in y_values.items():
#             df_copy[y_value[0]] = df_copy.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
#
#     for idx, trial_group in trials_group:
#         if idx[1] not in size:
#             continue
#         dfs = {}
#         dfs_new = []
#         for y in y_values:
#             dfs[y] = pd.DataFrame(columns=error_types)
#
#             for error_type in error_types:
#                 zero_cols = [e for e in error_types if e != error_type]
#                 df_for_err = trial_group
#                 for col in zero_cols:
#                     df_for_err = df_for_err[df_for_err[col] == 0]
#
#                 for error_value in error_values:
#                     df_for_err_filtered = df_for_err.where(df_for_err[error_type] == error_value)
#                     df_for_err_filtered = df_for_err_filtered[
#                         df_for_err_filtered['number_of_sampled_oligos_from_file'] == (samples[0])]
#                     dfs[y][error_type] = df_for_err_filtered[y].values
#             dfs_new.append(dfs[y].copy())
#
#
#         colors = ['blue', 'red', 'yellow']
#
#         df_out_before_rs = dfs_new[0]
#         df_out_after_rs_payload = dfs_new[1]
#         df_out_after_rs_wide = dfs = dfs_new[2]
#
#         my_dict = {}
#         for error_type, color in zip(error_types, colors):
#             my_dict[error_type] = {'Before 2D RS decoding\n(iv)': df_out_before_rs[error_type].values,
#                        'After RS payload decoding\n(iii)': df_out_after_rs_payload[error_type].values,
#                        'After 2D RS decoding\n(ii)': df_out_after_rs_wide[error_type].values}
#         for error_type in error_types:
#             fig, ax = plt.subplots(constrained_layout=True)
#             if percentage:
#                 array_estimate = []
#                 for dict_value in list(my_dict[error_type].values()):
#                     array_estimate.append([estimate(dict_value)])
#
#                 # Convert the array estimate into a dataframe
#                 df_estimate = pd.DataFrame(array_estimate)
#
#                 # Plotting the boxplot
#                 ax.boxplot(df_estimate.values.T, labels=my_dict[error_type].keys())
#                 ax.set_xticks(range(1, len(my_dict[error_type]) + 1))
#                 ax.set_xticklabels(my_dict[error_type].keys())
#                 title = 'Full reconstruction rates during the EC process ' + error_type
#                 ax.set_ylabel('Full reconstruction rate')
#
#             else:
#                 ax.boxplot(my_dict[error_type].values(), positions=range(len(my_dict[error_type])), widths=0.6)
#                 ax.set_xticks(range(len(my_dict[error_type])))
#                 ax.set_xticklabels(my_dict[error_type].keys())
#                 title = title_start_name + 'Reconstruction rates during the EC process ' + error_type
#                 ax.set_ylabel(title_start_name + 'Levenshtein distance')
#
#             fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
#             plt.close(fig)
#
#
# def draw_sampled_vs_error(df: pd.DataFrame):
#     fig, ax = plt.subplots()
#     ax = sns.boxplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, ax=ax,
#                      palette="Purples")
#     ax = sns.swarmplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, color=".25", ax=ax)
#     ax.set(xlabel="number_of_sampled_oligos_from_file".replace("_", " "), ylabel="D [levenshtein]")
#     fig.savefig(Path("data/testing/plots") / "number of sampled oligos and levenshtein distance")
#     plt.close(fig)
#
#
# def estimate(x):
#     res = sum(x == 0) * 100.0 / len(x)
#     return res
#
#
# def draw_zero_error_percentage(df: pd.DataFrame):
#     fig, ax = plt.subplots()
#     sns.barplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, estimator=estimate, ax=ax,
#                 palette="Blues")
#     ax.set(xlabel="number_of_sampled_oligos_from_file".replace("_", " "), ylabel="D% [levenshtein]")
#     fig.savefig(Path("data/testing/plots") / "number of sampled oligos and levenshtein distance success")
#     plt.close(fig)
#
#
# def draw_error_per_number_of_sampled_oligos(df: pd.DataFrame):
#     for idx, row in df.iterrows():
#         if row["substitution_error"] != 0:
#             df.loc[idx, "error_type"] = "substitution_error"
#             df.loc[idx, "error"] = row["substitution_error"]
#         elif row["deletion_error"] != 0:
#             df.loc[idx, "error_type"] = "deletion_error"
#             df.loc[idx, "error"] = row["deletion_error"]
#         elif row["insertion_error"] != 0:
#             df.loc[idx, "error_type"] = "insertion_error"
#             df.loc[idx, "error"] = row["insertion_error"]
#         else:
#             df.loc[idx, "error_type"] = "no_error"
#             df.loc[idx, "error"] = 0
#
#     fig, ax = plt.subplots()
#     ax = sns.catplot(
#         data=df,
#         x="number_of_sampled_oligos_from_file",
#         y="levenshtein_distance",
#         row="error_type",
#         col="error",
#         palette="Purples",
#         kind="bar",
#     )
#     ax.set(xlabel="error_per_number_of_sampled_oligos".replace("_", " "), ylabel="D [levenshtein]")
#     fig.savefig(Path("data/testing/plots") / "error_per_number_of_sampled_oligos")
#
#     fig = px.bar(
#         df, x="number_of_sampled_oligos_from_file", y="levenshtein_distance",
#         facet_row="error_type", facet_col="error",
#         barmode="group",
#     )
#     fig.show()
#
#
# def main():
#     plt.ion()
#     # df_reads = load_sorted_oligos_to_df()
#     # draw_reads_histograms(df=df_reads)
#
#     # df = load_data_to_df()
#     df = pd.read_csv(f'{OUTPUT_FOLDER}/df_all_data.csv')
#     # draw_zero_error_percentage(df=df)
#     # draw_boxplots(df=df)
#     # draw_boxplots(df=df, percentage=True)
#     # draw_boxplots_all_samples(df=df)
#     # draw_boxplots_all_samples(df=df, percentage=True)
#     # draw_lineplot_before_after_rs(df=df)
#     # draw_sampled_vs_error(df=df)
#     # draw_error_per_number_of_sampled_oligos(df=df)
#
#     '''Graphs in paper'''
#     # draw_errorbar_10_100sample_and_0_001_error_errortypes(df=df)
#     # draw_errorbar_in_one_graph(df=df)
#     draw_errorbar_in_one_graph(df=df, is_normalize_data=True)
#     # draw_errorbar_before_after_rs(df=df, percentage=True)
#     # draw_errorbar_before_after_rs(df=df)
#
#
#     draw_errorbar_in_one_graph(df=df, is_normalize_data=True)
#     draw_barplot_before_after_rs(df=df, percentage=True)
#     draw_barplot_before_after_rs(df=df, is_normalize_data=False)
#     draw_barplot_before_after_rs(df=df, is_normalize_data=True)
#     # input("Hit enter to terminate")
#
#
# if __name__ == '__main__':
#     main()

import gzip
import json
import re
import uuid
from pathlib import Path
from textwrap import wrap
import os

import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import numpy as np

sns.set_theme(style="ticks")

Path("data/testing/plots").mkdir(parents=True, exist_ok=True)

OUTPUT_FOLDER = Path(os.path.join('..', 'tests', 'data', 'testing')) # TODO: change it to the dir above data/testing/plots


def delete_double_gz() -> pd.DataFrame:
    output_dir = Path("data/testing")
    run_dirs = list(f for f in output_dir.iterdir() if f.name.startswith("["))
    for run_dir in run_dirs:
        files = list(run_dir.iterdir())
        for file in files:
            suffixes = file.suffixes
            if len(suffixes) > 1 and suffixes[-1] == ".gz" and suffixes[-2] == ".gz":
                with gzip.open(file, "rb") as f_in, open(file.with_suffix(""), "wb") as f_out:
                    f_out.writelines(f_in)
                os.remove(file)


def load_sorted_oligos_to_df() -> pd.DataFrame:
    import csv
    output_dir = Path("data/testing")
    run_dirs = list(f for f in output_dir.iterdir() if f.name.startswith("SS"))
    sorted_files = []

    for run_dir in run_dirs:
        try:
            sorted_file = [f for f in run_dir.iterdir() if "sort_oligo_results_file" in f.name][0]
        except IndexError:
            continue
        sorted_files.append(sorted_file)
    print(f'sort_oligo_results_file')
    info_list = []

    with open("sorted_oligos.csv", 'w') as csvfile:
        fieldnames = ["uid", "barcode", "read_len"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for sorted_file in sorted_files:
            uid = uuid.uuid4()
            try:
                with gzip.open(sorted_file, "rb") as f:
                    for line in f:
                        line = line.strip()
                        writer.writerow({
                            "uid": uid,
                            "barcode": line[:12].decode(),
                            "read_len": len(line[12:]),
                        })
            except:
                print(sorted_file)
                print(line)

    print(f'info_list')

    df_reads = pd.read_csv("sorted_oligos.csv")
    return df_reads


def draw_reads_histograms(df: pd.DataFrame):
    plt.subplots()
    fig = sns.histplot(df["read_len"], kde=False)
    fig.set_ylabel("count")
    fig = plt.gcf()
    fig.savefig(Path("data/testing/plots") / "read_len_count")

    groups = df.groupby(["uid", "barcode"])
    reads_per_barcode = []
    for _, group in groups:
        reads_per_barcode.append({"reads": len(group)})

    plt.subplots()
    # how many lines (sequences) was read per each barcode.
    # (That's why we have concentrations around 20, 50, 100, 1000)
    df_reads_per_barcode = pd.DataFrame(reads_per_barcode)
    fig = sns.histplot(df_reads_per_barcode["reads"], kde=False, binwidth=1)
    fig.set_ylabel("count")
    fig.set_xlabel("number of reads per barcode")
    fig = plt.gcf()
    fig.savefig(Path("data/testing/plots") / "number of reads per barcode")


def load_data_to_df() -> pd.DataFrame:
    # output_dir = Path("data/testing")

    run_dirs = list(f for f in OUTPUT_FOLDER.iterdir() if f.name.startswith("[SS"))

    json_files = []

    for run_dir in run_dirs:
        try:
            json_file = [f for f in run_dir.iterdir() if f.suffix == ".json"][0]
        except IndexError:
            continue
        json_files.append(json_file)

    info_list = []

    for json_file in json_files:
        with json_file.open("rb") as f:
            info = json.load(f)
        info_list.append(info)

    df = pd.DataFrame(info_list)
    df["output_dir"] = df["output_dir"].apply(lambda x: x.split("data/testing/")[1].split(" trial")[0])

    df.to_csv(f'{OUTPUT_FOLDER}/df_all_data.csv', index=False)
    return df


def draw_boxplots(df: pd.DataFrame, percentage: bool = False):
    trials_group = df.groupby([
        'number_of_oligos_per_barcode',
        'number_of_sampled_oligos_from_file',
        'size',
        'bits_per_z'
    ])

    errors = ["substitution_error", "deletion_error", "insertion_error"]
    y_values = ["levenshtein_distance", "levenshtein_distance_sigma_before_rs",
                "levenshtein_distance_sigma_after_rs_payload", "levenshtein_distance_sigma_after_rs_wide"]
    for y in y_values:
        if y == "levenshtein_distance":
            palette = "Purples"
        else:
            palette = "Blues"
        for idx, trial_group in trials_group:
            fig, axes = plt.subplots(nrows=3)
            fig.suptitle("\n".join(
                wrap(trial_group["output_dir"].iloc[0].split("errorsSub")[0] + f"\n{y}".replace("_", " "), 71)))
            fig.subplots_adjust(top=0.85, hspace=0.5)
            for ax, error in zip(axes, errors):
                zero_cols = [e for e in errors if e != error]
                df_for_err = trial_group
                for col in zero_cols:
                    df_for_err = df_for_err[df_for_err[col] == 0]
                if percentage:
                    ×–ax = sns.barplot(x=error, y=y, data=df_for_err, estimator=estimate, ax=ax, palette=palette)
                    ax.set(ylabel="Full reconstraction rate")
                else:
                    ax = sns.boxplot(x=error, y=y, data=df_for_err, ax=ax, palette=palette)
                    ax = sns.swarmplot(x=error, y=y, data=df_for_err, color=".25", ax=ax)
                    ax.set(ylabel="Normlized Levenshtein distance")
            if percentage:
                fig.savefig(Path("data/testing/plots") / " ".join(wrap(
                    trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
                                                                                                      " ") + f"{y} success",
                    71)))
                plt.close(fig)
            else:
                fig.savefig(Path("data/testing/plots") / "".join(wrap(
                    trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
                                                                                                      " ") + f"{y}",
                    71)))
                plt.close(fig)


def draw_boxplots_all_samples(df: pd.DataFrame, percentage: bool = False):
    trials_group = df.groupby([
        'number_of_oligos_per_barcode',
        'size',
        'bits_per_z'
    ])

    errors = ["substitution_error", "deletion_error", "insertion_error"]
    y_values = {"levenshtein_distance": "input_text_len",
                "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
                "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
                "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
                }
    for y_value in y_values.items():
        df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
    for y in y_values:
        if y == "levenshtein_distance":
            palette = "Purples"
        else:
            palette = "Blues"
        for idx, trial_group in trials_group:
            fig, axes = plt.subplots(nrows=3)
            title = trial_group["output_dir"].iloc[0].split("errorsSub")[0] + f"\n{y}".replace("_", " ")
            title = re.sub(r'\[ number of oligos sampled after synthesis[^\S\n\t]+\d+[^\S\n\t]+\]', '', title)
            fig.suptitle("\n".join(wrap(title, 71)))
            fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
            for ax_idx, (ax, error) in enumerate(zip(axes, errors)):
                zero_cols = [e for e in errors if e != error]
                df_for_err = trial_group
                for col in zero_cols:
                    df_for_err = df_for_err[df_for_err[col] == 0]
                if percentage:
                    ax = sns.barplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err,
                                     estimator=estimate, ax=ax, palette=palette)
                    ax.set(ylabel="Full reconstraction rate")
                else:
                    ax = sns.boxplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err, ax=ax,
                                     palette=palette)
                    # ax = sns.swarmplot(x=error, y=y, hue="number_of_sampled_oligos_from_file", data=df_for_err, ax=ax, dodge=True, palette=palette)
                    ax.set(ylabel="Normlized Levenshtein distance")
                if ax_idx != 0:
                    ax.get_legend().remove()
                else:
                    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
            if percentage:
                fig.savefig(Path("data/testing/plots") / " ".join(wrap(
                    trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
                                                                                                      " ") + f"{y} success",
                    71)))
                plt.close(fig)
            else:
                fig.savefig(Path("data/testing/plots") / "".join(wrap(
                    trial_group["output_dir"].iloc[0].split("errorsSub")[0].replace("[", " ").replace("]",
                                                                                                      " ") + f"{y}",
                    71)))
                plt.close(fig)


'''
Fig 1:
Title = Normalized LD as a function of sample size (No error correction)
Subplots = error type (share X axis, X-ticks only on the buttom, no titles for subplots)
X = number of reads (10-100)
Y = Normalized distance (with error bars)
Color = error level {0,0.01}
Filter: size = 5
Caption: ...'''


def draw_errorbar_10_100sample_and_0_001_error_errortypes(df: pd.DataFrame, percentage: bool = False):
    samples = [10, 20, 50, 100]
    error_values = [0.01, 0]
    size = [5]

    trials_group = df.groupby([
        'number_of_oligos_per_barcode',
        'size',
        'bits_per_z'
    ])

    error_types = ["substitution_error", "deletion_error", "insertion_error"]
    y_values = {
        "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len"
    }
    colors = ['-b', '-r']

    plt.figure(figsize=(20, 15))

    for y_value in y_values.items():
        df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)
    for idx, trial_group in trials_group:
        if idx[1] not in size:
            continue

        title = 'Normalized LD as a function of sample size (No error correction)'
        # fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
        for ax_idx, error_type in enumerate(error_types):
            plt.subplot(3, 1, (ax_idx + 1))
            zero_cols = [e for e in error_types if e != error_type]
            df_for_err = trial_group
            for col in zero_cols:
                df_for_err = df_for_err[df_for_err[col] == 0]

            # Filter by cols error_value and number_of_sampled_oligos_from_file
            for error_value, color_value in zip(error_values, colors):
                df_for_err_filtered = df_for_err.where(df_for_err[error_type] == error_value)
                df_for_err_filtered = df_for_err_filtered[
                    df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]

                grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
                    'levenshtein_distance_sigma_before_rs'].apply(list)
                result = {key: value for key, value in grouped.to_dict().items()}

                std_error = np.std(list(result.values()), axis=1)
                mean_error = np.mean(list(result.values()), axis=1)

                plt.errorbar(samples, mean_error, yerr=std_error, fmt=color_value, markersize=15,
                             elinewidth=1, capsize=3, label=0, linewidth=3)

            ylim = [-0.01, 1]
            yticks = np.linspace(0, 1, 6)
            plt.ylim(ylim)
            plt.yticks(yticks)
            plt.title(error_type.replace("_", " "), size=20)
            plt.legend(error_values, title='Error rate', prop={'size': 15}, title_fontsize=15)

        plt.text(20, 3.6, title, va='bottom', rotation='horizontal', fontsize=30)
        plt.text(35, -0.3, 'Number of sampled oligos from file', va='bottom', rotation='horizontal', fontsize=30)
        plt.text(-0.1, 1.8, 'Normlized Levenshtein distance', va='center', rotation='vertical', ha='right', fontsize=30)
        plt.savefig(Path("data/testing/plots") / "".join(wrap(title, 71)))
        plt.close()


# Fig draw_lineplot_in_one_graph:
# Title = Normalized LD as a function of sample size error=0.01 (No error correction)
# X = number of reads (10-100)
# Y = Normalized distance (with error bars, show the zero!)
# Color = error type {S,I,D}
# Filter: size = 5
def draw_errorbar_in_one_graph(df: pd.DataFrame, is_normalize_data, percentage: bool = False):
    # samples = [10, 20, 50, 100]
    samples = [6, 10, 15, 20, 25, 30, 35, 40]
    error_values = [0.01]
    size = [4]
    title_start = ""

    trials_group = df.groupby([
        'number_of_oligos_per_barcode',
        'size',
        'bits_per_z'
    ])

    errors = ["substitution_error", "deletion_error", "insertion_error"]
    y_values = {
        "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
        "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
        "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
    }
    if is_normalize_data:
        title_start = "Normalized "
        for y_value in y_values.items():
            df[y_value[0]] = df.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)

    for idx, trial_group in trials_group:
        if idx[1] not in size:
            continue
        for y_value in y_values.keys():
            title = title_start + "LD as a function of sample size. Error=0.01, 0 (No error correction)\n" + y_value
            fig, ax = plt.subplots(figsize=(8, 6))

            fig.subplots_adjust(top=0.85, hspace=0.5, right=0.8)
            for ax_idx, error in enumerate(errors):
                zero_cols = [e for e in errors if e != error]
                df_for_err = trial_group
                for col in zero_cols:
                    df_for_err = df_for_err[df_for_err[col] == 0]

                if error == "deletion_error":
                    error_values.append(0)

                for error_value in error_values:
                    df_for_err_filtered = df_for_err.where(df_for_err[error] == error_value)
                    df_for_err_filtered = df_for_err_filtered[
                        df_for_err_filtered['number_of_sampled_oligos_from_file'].isin(samples)]

                    grouped = df_for_err_filtered.groupby('number_of_sampled_oligos_from_file')[
                        y_value].apply(list)
                    result = {key: value for key, value in grouped.to_dict().items()}

                    std_error = np.std(list(result.values()), axis=1)
                    mean_error = np.mean(list(result.values()), axis=1)

                    if error == "deletion_error" and error_value == 0:
                        plt.errorbar(samples, mean_error + 0.004, yerr=std_error, markersize=15,
                                     elinewidth=1, capsize=3,
                                     label='all errors' + ' ' + str(error_value), linewidth=3)
                    else:
                        plt.errorbar(samples, mean_error, yerr=std_error, markersize=15,
                                     elinewidth=1, capsize=3, label=error.replace("_error", "")+' '+str(error_value), linewidth=3)

                if error == "deletion_error":  # reset your error_values list after processing substitution_error
                    error_values.remove(0)

                plt.legend()
                ax.set_xlabel('sampled oligos from file', x=0.5, y=-5)
                ax.set_ylabel(title_start+'Levenshtein distance')

                if is_normalize_data:
                    ax.set_ylim(-0.01, 1)
                else:
                    ax.set_ylim(-0.01, 10000)

            # plt.title(title)
            fig.tight_layout()
            fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
            plt.close(fig)


# Fig draw_lineplot_before_after_rs:
# Title = Reconstruction rates during the EC process
# X = EC step {Raw input, After RS1, After 2D RS}
# Y = Reconstruction rate (with error bars)
# Color = error type {S,I,D}
# Filter: size = 5, sample size = 50,

def draw_barplot_before_after_rs(df: pd.DataFrame, percentage: bool = False, is_normalize_data: bool = True):
    samples = [20]
    error_values = [0.01]
    size = [4]

    df_copy = df.copy(deep=True)
    title_start_name = ""

    trials_group = df_copy.groupby([
        'number_of_oligos_per_barcode',
        'size',
        'bits_per_z'
    ])
    error_types = ["substitution_error", "deletion_error", "insertion_error"]

    y_values = {
        "levenshtein_distance_sigma_before_rs": "input_data_encoder_results_file_len",
        "levenshtein_distance_sigma_after_rs_payload": "input_data_encoder_without_rs_payload_len",
        "levenshtein_distance_sigma_after_rs_wide": "input_data_encoder_without_rs_wide_len"
    }
    if is_normalize_data:
        title_start_name = 'Normalized '
        for y_value in y_values.items():
            df_copy[y_value[0]] = df_copy.apply(lambda x: x[y_value[0]] / x.get(y_value[1], 1), axis=1)

    for idx, trial_group in trials_group:
        if idx[1] not in size:
            continue
        dfs = {}
        dfs_new = []
        for y in y_values:
            dfs[y] = pd.DataFrame(columns=error_types)

            for error_type in error_types:
                zero_cols = [e for e in error_types if e != error_type]
                df_for_err = trial_group
                for col in zero_cols:
                    df_for_err = df_for_err[df_for_err[col] == 0]

                for error_value in error_values:
                    df_for_err_filtered = df_for_err.where(df_for_err[error_type] == error_value)
                    df_for_err_filtered = df_for_err_filtered[
                        df_for_err_filtered['number_of_sampled_oligos_from_file'] == (samples[0])]
                    dfs[y][error_type] = df_for_err_filtered[y].values
            dfs_new.append(dfs[y].copy())


        colors = ['blue', 'red', 'yellow']

        df_out_before_rs = dfs_new[0]
        df_out_after_rs_payload = dfs_new[1]
        df_out_after_rs_wide = dfs = dfs_new[2]

        my_dict = {}
        for error_type, color in zip(error_types, colors):
            my_dict[error_type] = {'Before 2D RS decoding\n(iv)': df_out_before_rs[error_type].values,
                       'After RS payload decoding\n(iii)': df_out_after_rs_payload[error_type].values,
                       'After 2D RS decoding\n(ii)': df_out_after_rs_wide[error_type].values}
        for error_type in error_types:
            fig, ax = plt.subplots(constrained_layout=True)
            if percentage:
                array_estimate = []
                for dict_value in list(my_dict[error_type].values()):
                    array_estimate.append([estimate(dict_value)])

                # Convert the array estimate into a dataframe
                df_estimate = pd.DataFrame(array_estimate)

                # Plotting the boxplot
                ax.boxplot(df_estimate.values.T, labels=my_dict[error_type].keys())
                ax.set_xticks(range(1, len(my_dict[error_type]) + 1))
                ax.set_xticklabels(my_dict[error_type].keys())
                title = 'Full reconstruction rates during the EC process ' + error_type
                ax.set_ylabel('Full reconstruction rate')

            else:
                ax.boxplot(my_dict[error_type].values(), positions=range(len(my_dict[error_type])), widths=0.6)
                ax.set_xticks(range(len(my_dict[error_type])))
                ax.set_xticklabels(my_dict[error_type].keys())
                title = title_start_name + 'Reconstruction rates during the EC process ' + error_type
                ax.set_ylabel(title_start_name + 'Levenshtein distance')

            fig.savefig(Path("data/testing/plots") / "".join(wrap(title + ".svg", 71)))
            plt.close(fig)


def draw_sampled_vs_error(df: pd.DataFrame):
    fig, ax = plt.subplots()
    ax = sns.boxplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, ax=ax,
                     palette="Purples")
    ax = sns.swarmplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, color=".25", ax=ax)
    ax.set(xlabel="number_of_sampled_oligos_from_file".replace("_", " "), ylabel="D [levenshtein]")
    fig.savefig(Path("data/testing/plots") / "number of sampled oligos and levenshtein distance")
    plt.close(fig)


def estimate(x):
    res = sum(x == 0) * 100.0 / len(x)
    return res


def draw_zero_error_percentage(df: pd.DataFrame):
    fig, ax = plt.subplots()
    sns.barplot(x="number_of_sampled_oligos_from_file", y="levenshtein_distance", data=df, estimator=estimate, ax=ax,
                palette="Blues")
    ax.set(xlabel="number_of_sampled_oligos_from_file".replace("_", " "), ylabel="D% [levenshtein]")
    fig.savefig(Path("data/testing/plots") / "number of sampled oligos and levenshtein distance success")
    plt.close(fig)


def draw_error_per_number_of_sampled_oligos(df: pd.DataFrame):
    for idx, row in df.iterrows():
        if row["substitution_error"] != 0:
            df.loc[idx, "error_type"] = "substitution_error"
            df.loc[idx, "error"] = row["substitution_error"]
        elif row["deletion_error"] != 0:
            df.loc[idx, "error_type"] = "deletion_error"
            df.loc[idx, "error"] = row["deletion_error"]
        elif row["insertion_error"] != 0:
            df.loc[idx, "error_type"] = "insertion_error"
            df.loc[idx, "error"] = row["insertion_error"]
        else:
            df.loc[idx, "error_type"] = "no_error"
            df.loc[idx, "error"] = 0

    fig, ax = plt.subplots()
    ax = sns.catplot(
        data=df,
        x="number_of_sampled_oligos_from_file",
        y="levenshtein_distance",
        row="error_type",
        col="error",
        palette="Purples",
        kind="bar",
    )
    ax.set(xlabel="error_per_number_of_sampled_oligos".replace("_", " "), ylabel="D [levenshtein]")
    fig.savefig(Path("data/testing/plots") / "error_per_number_of_sampled_oligos")

    fig = px.bar(
        df, x="number_of_sampled_oligos_from_file", y="levenshtein_distance",
        facet_row="error_type", facet_col="error",
        barmode="group",
    )
    fig.show()


def main():
    plt.ion()
    # df_reads = load_sorted_oligos_to_df()
    # draw_reads_histograms(df=df_reads)

    df = load_data_to_df()
    df = pd.read_csv(f'{OUTPUT_FOLDER}\df_all_data.csv')
    # draw_zero_error_percentage(df=df)
    # draw_boxplots(df=df)
    # draw_boxplots(df=df, percentage=True)
    # draw_boxplots_all_samples(df=df)
    # draw_boxplots_all_samples(df=df, percentage=True)
    # draw_lineplot_before_after_rs(df=df)
    # draw_sampled_vs_error(df=df)
    # draw_error_per_number_of_sampled_oligos(df=df)

    '''Graphs in paper'''
    # draw_errorbar_10_100sample_and_0_001_error_errortypes(df=df)
    # draw_errorbar_in_one_graph(df=df, is_normalize_data=False)
    draw_errorbar_in_one_graph(df=df, is_normalize_data=True)
    draw_barplot_before_after_rs(df=df, percentage=True)
    draw_barplot_before_after_rs(df=df, is_normalize_data=False)
    draw_barplot_before_after_rs(df=df, is_normalize_data=True)
    # input("Hit enter to terminate")


if __name__ == '__main__':
    main()
